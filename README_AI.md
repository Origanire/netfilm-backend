# Akinator IA - Documentation

## ğŸ“‹ Vue d'ensemble

Cette version modifiÃ©e du moteur Akinator utilise l'API Claude d'Anthropic pour gÃ©rer intelligemment les questions et les rÃ©ponses, au lieu d'utiliser un systÃ¨me de probabilitÃ©s local. L'IA analyse la base de donnÃ©es de films et pose des questions stratÃ©giques pour deviner le film pensÃ© par l'utilisateur.

## ğŸ”‘ CaractÃ©ristiques principales

### âœ… Avantages par rapport Ã  la version originale

1. **Intelligence contextuelle**: L'IA comprend le contexte et adapte ses questions
2. **Questions naturelles**: Formulation plus humaine et conversationnelle
3. **Pas de maintenance de rÃ¨gles**: L'IA s'adapte automatiquement sans coder de nouvelles rÃ¨gles
4. **Apprentissage continu**: L'IA amÃ©liore sa stratÃ©gie au fil de la conversation
5. **CompatibilitÃ© frontend**: L'interface reste identique pour le frontend

### ğŸ¯ Comment Ã§a fonctionne

```
Utilisateur pense Ã  un film
        â†“
IA reÃ§oit la base de donnÃ©es de films
        â†“
IA pose des questions stratÃ©giques (genre, Ã©poque, acteurs, etc.)
        â†“
Utilisateur rÃ©pond: oui / non / je ne sais pas
        â†“
IA affine ses hypothÃ¨ses
        â†“
Quand confiance > 90% â†’ Proposition du film
        â†“
Confirmation ou continuation
```

## ğŸš€ Installation

### 1. PrÃ©requis

```bash
pip install requests --break-system-packages
```

### 2. Configuration de la clÃ© API

Vous devez obtenir une clÃ© API Anthropic sur: https://console.anthropic.com/

Puis la configurer:

```bash
export ANTHROPIC_API_KEY="votre_clÃ©_api_ici"
```

Ou dans votre fichier `.env`:

```
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx
```

### 3. Utilisation en ligne de commande

```bash
python engine_akinator_ai.py --db path/to/movies.db
```

## ğŸ”Œ IntÃ©gration avec votre Backend

### Option 1: Remplacement complet

Remplacez simplement `engine_akinator.py` par `engine_akinator_ai.py`:

```bash
cp engine_akinator_ai.py backend/engines/engine_akinator.py
```

### Option 2: Utilisation en parallÃ¨le

Gardez les deux versions et utilisez l'IA via une route API dÃ©diÃ©e.

### Exemple d'intÃ©gration FastAPI/Flask

```python
from engine_akinator_ai import AkinatorSession

# Stockage des sessions (en production, utilisez Redis ou similaire)
sessions = {}

@app.post("/api/akinator/start")
async def start_akinator():
    """DÃ©marre une nouvelle session Akinator."""
    session_id = generate_session_id()
    session = AkinatorSession(db_path="path/to/movies.db")
    
    result = session.start()
    sessions[session_id] = session
    
    return {
        "session_id": session_id,
        **result
    }

@app.post("/api/akinator/answer")
async def answer_question(session_id: str, answer: str):
    """Envoie une rÃ©ponse et obtient la prochaine question."""
    session = sessions.get(session_id)
    if not session:
        return {"error": "Session invalide"}
    
    result = session.answer(answer)
    return result

@app.post("/api/akinator/confirm")
async def confirm_guess(session_id: str, is_correct: bool):
    """Confirme si la proposition Ã©tait correcte."""
    session = sessions.get(session_id)
    if not session:
        return {"error": "Session invalide"}
    
    result = session.confirm(is_correct)
    
    # Si trouvÃ©, supprimer la session
    if result.get("result") == "found":
        del sessions[session_id]
    
    return result
```

## ğŸ“¡ Format des rÃ©ponses API

### 1. DÃ©marrage de session (`/start`)

```json
{
  "status": "ok",
  "action": "question",
  "content": "Est-ce un film d'action ?",
  "question_number": 1,
  "total_movies": 15432
}
```

### 2. RÃ©ponse Ã  une question (`/answer`)

**Question suivante:**
```json
{
  "status": "ok",
  "action": "question",
  "content": "Le film est-il sorti aprÃ¨s 2010 ?",
  "question_number": 2
}
```

**Proposition de film:**
```json
{
  "status": "ok",
  "action": "guess",
  "content": "Inception",
  "question_number": 5
}
```

### 3. Confirmation (`/confirm`)

**Film trouvÃ©:**
```json
{
  "status": "ok",
  "result": "found",
  "questions_asked": 7
}
```

**Continuer:**
```json
{
  "status": "ok",
  "result": "continue",
  "action": "question",
  "content": "Y a-t-il Leonardo DiCaprio dans ce film ?",
  "question_number": 8
}
```

## ğŸ® CompatibilitÃ© Frontend

Le frontend n'a **aucune modification** Ã  faire ! L'API reste compatible:

### Flux de communication

```javascript
// 1. DÃ©marrer le jeu
const response = await fetch('/api/akinator/start', { method: 'POST' });
const data = await response.json();
// data.content contient la question

// 2. RÃ©pondre Ã  une question
const answer = await fetch('/api/akinator/answer', {
  method: 'POST',
  body: JSON.stringify({
    session_id: sessionId,
    answer: 'y' // ou 'n' ou '?'
  })
});

// 3. Si action === "guess", confirmer
if (data.action === 'guess') {
  const confirm = await fetch('/api/akinator/confirm', {
    method: 'POST',
    body: JSON.stringify({
      session_id: sessionId,
      is_correct: true
    })
  });
}
```

## âš™ï¸ Configuration avancÃ©e

### Personnalisation du modÃ¨le IA

Dans `engine_akinator_ai.py`, vous pouvez changer:

```python
# Utiliser un modÃ¨le diffÃ©rent
AI_MODEL = "claude-sonnet-4-20250514"  # Rapide et intelligent
# ou
AI_MODEL = "claude-opus-4-5-20251101"   # Plus puissant mais plus lent
```

### Limitation du nombre de films

Pour des rÃ©ponses plus rapides et moins coÃ»teuses:

```python
def initialize_game(self, movies: List[dict]):
    # Limiter Ã  1000 films populaires au lieu de tous
    self.movies_database = movies[:1000]
```

## ğŸ’° CoÃ»t estimÃ©

Avec l'API Claude:
- **Claude Sonnet 4**: ~$3 / million de tokens input, ~$15 / million de tokens output
- **Partie moyenne**: ~5-10 questions = ~2000 tokens total
- **CoÃ»t par partie**: ~$0.001 - $0.003 (0.1 Ã  0.3 centimes)

Pour 1000 parties/jour: ~$1-3/jour

## ğŸ”’ SÃ©curitÃ©

### Variables d'environnement

**Ne JAMAIS** commiter votre clÃ© API dans le code !

Utilisez:
```bash
# .env
ANTHROPIC_API_KEY=sk-ant-xxxxx

# Ou variables d'environnement systÃ¨me
export ANTHROPIC_API_KEY="sk-ant-xxxxx"
```

### Limitation de taux

L'API Anthropic a des limites:
- RequÃªtes/minute: Varie selon votre plan
- ImplÃ©mentez un rate limiting cÃ´tÃ© serveur

```python
from functools import lru_cache
from time import time

@lru_cache(maxsize=100)
def rate_limit(session_id: str, timestamp: int) -> bool:
    # Limiter Ã  1 requÃªte par seconde
    return True
```

## ğŸ› Debugging

### Mode verbose

Ajoutez des logs pour debug:

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Dans la classe AkinatorAI
def _call_anthropic_api(self, user_message: str) -> str:
    logging.debug(f"Envoi Ã  l'IA: {user_message}")
    response = ...
    logging.debug(f"RÃ©ponse de l'IA: {response}")
    return response
```

### Test sans API

Pour tester sans consommer de crÃ©dits API:

```python
class MockAkinatorAI(AkinatorAI):
    def _call_anthropic_api(self, user_message: str) -> str:
        # Retourner des rÃ©ponses mockÃ©es
        return "QUESTION: Est-ce un film d'action ?"
```

## ğŸ“Š Monitoring

### MÃ©triques Ã  surveiller

1. **Temps de rÃ©ponse API**: Doit Ãªtre < 3 secondes
2. **Taux de rÃ©ussite**: % de films trouvÃ©s
3. **Nombre moyen de questions**: Objectif < 15
4. **CoÃ»t par partie**: Pour optimisation budget

### Exemple de logging

```python
import time

class AkinatorSession:
    def __init__(self):
        self.start_time = time.time()
        self.api_calls = 0
    
    def answer(self, response: str):
        self.api_calls += 1
        result = ...
        
        # Log metrics
        duration = time.time() - self.start_time
        print(f"Session: {self.api_calls} calls, {duration:.2f}s")
        
        return result
```

## ğŸš¨ Gestion d'erreurs

### Timeout API

```python
try:
    response = requests.post(
        ANTHROPIC_API_URL, 
        headers=headers, 
        json=payload, 
        timeout=10  # 10 secondes max
    )
except requests.exceptions.Timeout:
    return {
        "status": "error",
        "message": "L'IA met trop de temps Ã  rÃ©pondre, rÃ©essayez"
    }
```

### Limite de tokens dÃ©passÃ©e

```python
try:
    result = response.json()
except Exception as e:
    if "max_tokens" in str(e):
        # Augmenter max_tokens ou rÃ©duire l'historique
        pass
```

## ğŸ“ Exemples de questions gÃ©nÃ©rÃ©es par l'IA

L'IA adapte ses questions selon le contexte:

**DÃ©but de partie (questions larges):**
- "Est-ce un film d'action ?"
- "Le film est-il sorti aprÃ¨s 2010 ?"
- "S'agit-il d'un film amÃ©ricain ?"

**Milieu de partie (questions ciblÃ©es):**
- "Y a-t-il des super-hÃ©ros dans ce film ?"
- "Le film se passe-t-il dans l'espace ?"
- "Est-ce un film de Christopher Nolan ?"

**Fin de partie (questions trÃ¨s spÃ©cifiques):**
- "Leonardo DiCaprio joue-t-il dans ce film ?"
- "Le film parle-t-il de rÃªves ?"
- "Le film s'appelle-t-il Inception ?"

## ğŸ“ Conseils d'optimisation

### 1. Cache des rÃ©sultats frÃ©quents

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_movie_info(movie_id: int) -> dict:
    # Cache les infos de films frÃ©quemment demandÃ©s
    return get_details(conn, movie_id)
```

### 2. PrÃ©-calcul des mÃ©tadonnÃ©es

```python
# Au dÃ©marrage, calculer les stats
movie_stats = {
    "by_genre": count_by_genre(movies),
    "by_decade": count_by_decade(movies),
    "by_language": count_by_language(movies)
}
```

### 3. Compression de l'historique

```python
# Garder seulement les N derniers messages
MAX_HISTORY = 20

if len(self.conversation_history) > MAX_HISTORY:
    self.conversation_history = self.conversation_history[-MAX_HISTORY:]
```

## ğŸ”® AmÃ©liorations futures possibles

1. **Mode hybride**: Combiner IA + probabilitÃ©s pour plus de prÃ©cision
2. **Apprentissage des prÃ©fÃ©rences**: L'IA apprend du comportement utilisateur
3. **Multi-langues**: Questions en franÃ§ais, anglais, espagnol, etc.
4. **Suggestions intelligentes**: "Peut-Ãªtre avez-vous pensÃ© Ã ..."
5. **Mode compÃ©tition**: Comparer IA vs SystÃ¨me probabiliste

## ğŸ“ Support

Pour toute question ou problÃ¨me:
- GitHub Issues: [votre-repo]/issues
- Email: support@votre-domaine.com
- Documentation Anthropic: https://docs.anthropic.com/

---

**Version**: 1.0.0  
**DerniÃ¨re mise Ã  jour**: 2024  
**Licence**: MIT
